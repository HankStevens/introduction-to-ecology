[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "intro_to_ecology",
    "section": "",
    "text": "Preface\n\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0      ✔ purrr   1.0.1 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.5.0 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(dagitty)\nlibrary(ggdag)\n\n\nAttaching package: 'ggdag'\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n# library(rethinking)\nlibrary(googlesheets4)\n\nThis book provides an activity-based approach introduction to the science and practice of ecology. It is designed to form the basis of an undergraduate general ecology course. It includes real-world assessment activities, and so answer keys are not generally available, even if they might be appropriate in some situations.\nEach chapter provides,\n\nlinks to background information in the form of a video lecture, peer-reviewed publications, and sometimes other sources,\none or more writing assignments, and\ndata exploration and modeling.\n\nMy other books include A Primer of Ecology using R and A Primer of Ecosystem Modeling. The former (Primer of Ecology) is designed primarily for graduate students as a primer to theory in population community ecology. It was first published with Springer in 2009, and the current GitHub version is quite updated. I use the former (ecosystem modeling) when I co-instruct a graduate course led by colleagues who are real ecosystem ecologists (Drs. Melany Fisk, Mike Vanni, and Lesley Knoll).\nMazel tov!"
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee (knuth84?) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "4  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "01-trees_and_people.html#background",
    "href": "01-trees_and_people.html#background",
    "title": "2  Tree Cover: an investigation in ecology and in environmental justice",
    "section": "2.1 Background",
    "text": "2.1 Background\nThe types of places that organisms live–their habitats–depends on a variety factors. Selection of particular habitats results from tradeoffs between the benefits from foraging and reproducing versus perceived risks of mortality (Stephens and Krebs 1986; Morin 1999). Organisms also construct elements of their own habitats, including nests and burrows, as well as broader habitat alteration (niche construction, Odling-Smee and Erwin 2013). Beavers build dens and dams, birds and wasps build nests, and bacteria, ants, and humans all construct elaborate multi-layered cities of thousands or millions of individuals. At the same time, organisms often damage the very habitats they create, through over-consumption of resources and over-production of waste products. We know a great deal about how our own species (H. sapiens) construct elements of their own habitats. We also know a lot about how we migrate and disperse from place to place. Nonetheless, we have a lot to learn about our own species, and, in particular, about which factors determine the our preferred habitats and determine the changes we make to those habitats.\nEconomic wealth seems to influence many of choices by H sapiens, including our preferred habitats. Ed Wilson (1984), a famous evolutionary biologist, have proposed the Biophilia hypothesis, that humans love nature. Biomedical researchers have shown that we are happier and heal from injury and illness faster when we have access to plants and to the outdoors (Franklin 2012). If wealth generally gives us greater access to what we want, will wealthier people more often put themselves in closer connection to nature?\nSpecific socioeconomic data about H. sapiens populations may be particularly useful understanding both the causes and consequences of relations between wealth and nature. Wealth can be measured in a variety of ways. Median income, and percent of the population below the poverty line are common ways to measure the average wealth of individuals or small family groups.\nSpecific data about our landscapes maybe be particularly useful in generating ecological understanding of H. sapiens. Tree cover is the two-dimensional coverage of tree canopies that you would perceive in an aerial photo in seasons when trees have their leaves. Tree cover is relatively easy to measure from satellite imagery. Temperature, or the heat experienced by residents, can be a serious problem in urban areas because they create heat “islands”. Urban heat islands are areas which tend to absorb more solar radiation than would a natural landscape and then re-radiate this as heat experienced by its human and non-human residents. During heat waves, residents in urban areas who are especially vulnerable can suffer severe heat exhaustion or death. Some urban areas tend to get much hotter than others, and it is often related to tree cover and green space generally.\nTrees provide enormous ecosystem service benefits, including to help mitigate pollution via uptake of carbon dioxide and carbon monoxide (CO\\(_2\\) and CO) and other greehouse gases. Trees can also help reduce pollutants that cause direct negative effects on human health, such as fine and ultrafine particulate matter (PM\\(_{2.5}\\), PM\\(_{0.1}\\)).\nIn this research project, we will use freely available online data to address whether there is an association between wealth and the wild. Specifically, we will address whether, if we compare different geographic locations, will we see a relationship between the median income of an area, and the percent cover of trees? The data we collect will allow us to explore a variety of related ideas, but we will start with testing Wilson’s biophilia hypothesis, which predicts that humans love nature. We will test my corollary of this, that humans who have the greatest degree of freedom of choice (the wealthy) will tend to live in areas with the greatest connection to Nature (a lot of trees).\nView your mission here: \nor here:"
  },
  {
    "objectID": "01-trees_and_people.html#methods",
    "href": "01-trees_and_people.html#methods",
    "title": "2  Tree Cover: an investigation in ecology and in environmental justice",
    "section": "2.2 Methods",
    "text": "2.2 Methods\nWork in pairs. Share introductions with someone and get to work.\nWe will collect data on tree cover (%), heat, and wealth using two different platforms:\n\nTree Equity Score website\nOurTrees application in i-Tree\n\nThe first of these two platforms, Tree Equity Score, gives fairly detailed information on cities over 50,000 residents in size. It provides information related to environmental justice, including levels of poverty, tree cover, and heat. Our second data source is from i-Tree.org and it provides fairly detailed information about tree cover and the ecosystem services they provide. (Ecosystem services are features of ecosystems that benefit humans, such as storm water protection, and shade for buildings). i-Tree also provides median household income.\n\n2.2.1 Instructions\nTree Equity Score data\n\nGo to our class Google Sheet for Tree Equity Score cities, and enter the name of a city (pop. > 50,000) that you will investigate. It must be different than what anyone else has selected. Add your name to your selected city.\nGo to the Tree Equity Score website.\nSearch for your city.\nFind the data for the city: click on the map inside the area of your city. Note that a map will typically display more than just your city. It will also display adjacent regions. For instance, the map for “Cincinnati, OH” displays Hamilton County and Covington, KY. Selecting an area will cause a data summary window to pop up on the left side. Confirm that when you click on an area of the map, it is inside the city you intended.\nSelecting an area link to a Municipal Report. This report provides information for the city as a whole. Confirm that when you click on an area of the map, it is inside the city you intended. Select the link, Municipal Report.\nPick the data most relevant to our question: adjust the setting for the right-hand column graph to show Tree Cover (%) vs. People in Poverty %. You will use this column graph in addressing our overall question.\nThe Municipal Report provides a Tree Equity Score, urbanized area population estimate, percent seniors, and a percentage of people in poverty. Enter these into the Google Sheet. Add one Miami uniqueID per group to each observation (row).\nSave the web page as a PDF, and name it with the city name and “TES” (e.g., “Cincinnati_TES.pdf”). If you would like assistance saving the PDF, read the instructions under the button “Share report ->”. Make sure to close the instructions before you save the page. This file will be a record of your data.\nMake sure that you have entered the Tree Equity score and poverty percentage in the Google Sheet, and that you saved to your own computer your column graph of tree cover vs. percent of people in poverty.\n\nOurTrees app, in i-Tree\n\nOurTrees application in i-Tree. Select a location in which you are interested. Start with any lcoation name, and select “Search”. The app will show you a location. If you would like to, you can change the location by simply clicking somewhere else on the map. You can choose either Street view or Satellite view (the data will be the same).\nEnter the name of your selected location into our class a new spreadsheet, Google Sheet for OurTrees.\nIn the OurTrees app, select “Get Results! ->”.\nFrom the “Benefits” tab, collect data on tree canopy cover (%), annual uptake of CO\\(_2\\) equivalents and 2.5 micron particulate matter (PM\\(_{2.5}\\)). Enter these into the OurTrees Google Sheet.\nFrom the “Community” tab, collect data on total population size, number of seniors (>64), percent minority, median annual income, and percent impoverished. Enter these into the OurTrees Google Sheet.\nRepeat the above steps for nine more locations anywhere in the world. Your locations must be different than what anyone else has selected in the OurTrees spreadsheet. Add one Miami uniqueID per group to each observation (row).\n\n\n\n2.2.2 Graphing data to assess our predictions\nI argued that the Biophilia Hypothesis leads to the prediction that tree cover will correlate positively with wealth. To evaluate this prediction, we should make a graph in which wealth is on the x-axis (horizontal axis) and tree cover is y-axis (vertical axis).\nA couple of minor points: (1) Our prediction also implies that we should see a negative relation between poverty and tree cover. (2) We typically assume that the variable on the y-axis is a response to the variable on the x-axis, that is, that the x variable is causing variation in the y variable.\nGiven our data are continuous variables rather than categories, we should start by making a scatterplot of median income (x) vs. tree cover (y). Do that in anyway you like, such as in R, Google Sheets, or Microsoft Excel.\nAs the semester progresses, you will find R is very useful. Below, I provide you with code for an R script to easily make this graph.\n\n# if needed, install these packages\n# install.packages(\"googlesheets4\")\n# install.packages(\"ggplot2\")\n\n# load these packages\nlibrary(googlesheets4)\nlibrary(ggplot2)\n\n# Import data. \n# This code will require that you have permission to access our G-Sheet.\n# You may be asked to select various options and/or sign in to your\n# Miami Google account.\n\n# The function read_sheet() requires a Google Sheet URL in quotes, and\n# allows you to skip lines that are not data, \n# such as a table description.\n\nd <- read_sheet(\"https://docs.google.com/spreadsheets/d/1uYCuTziJiLNvVOQ9Q65BxdWcNgDF6EnF8L1T3O_yATw/edit#gid=0\",\n                skip=2)\n\n! Using an auto-discovered, cached token.\n\n\n  To suppress this message, modify your code or options to clearly consent to\n  the use of a cached token.\n\n\n  See gargle's \"Non-interactive auth\" vignette for more details:\n\n\n  <\u001b]8;;https://gargle.r-lib.org/articles/non-interactive-auth.html\u0007https://gargle.r-lib.org/articles/non-interactive-auth.html\u001b]8;;\u0007>\n\n\nℹ The googlesheets4 package is using a cached token for '\u001b]8;;mailto:stevenmh@miamioh.edu\u0007stevenmh@miamioh.edu\u001b]8;;\u0007'.\n\n\n✔ Reading from \"iTree_OurTrees - Spring 2023\".\n\n\n✔ Range '3:10000000'.\n\n# Uncomment to show us the names of the variables\n# names(d)\n\n# make a scatterplot\nggplot(data=d, aes(x=`Median Income`, \n                   y=`Tree canopy cover`, \n                   label=`City (only)`)) + geom_text() +\n  labs(y=\"Tree cover (%)\", x=\"Median income\")\n\n# save the figure (dimensions in inches)\nggsave(\"myCoverIncome.png\", width=6, height = 6)\n\n\n\n\nFigure 2.1: The noisy but perhaps positive relation between percent of an location covered in trees and the median income of that location.\n\n\n\n\nRefer to the scatterplot of my data (Figure 2.1). What do we find? Discuss the following questions with your colleagues, and propose and explain some possible answers.\n\nIs there a relationship that is consistent with our hypothesis? Does tree cover increase with income?\nNotice the cities that I selected. What else do you know about these locations, aside from income, that might influence tree cover?\nWhat else might be going on that helps create this relation or might obscure a stronger relation?\nAfter looking at these data, would you want to select locations in a different way?"
  },
  {
    "objectID": "01-trees_and_people.html#references",
    "href": "01-trees_and_people.html#references",
    "title": "2  Tree Cover: an investigation in ecology and in environmental justice",
    "section": "2.4 References",
    "text": "2.4 References\n\n\n\n\nFranklin, Deborah. 2012. “Nature That Nutures.” Scientific American 306 (3): 24–25.\n\n\nMorin, P J. 1999. Community Ecology. Malden, MA: Blackwell Science, Inc.\n\n\nOdling-Smee, J, and DH Erwin. 2013. “Niche Construction Theory: A Practical Guide for Ecologists.” The Quarterly Review of Biology 88 (1): 3–28.\n\n\nStephens, D W, and J R Krebs. 1986. Foraging Theory. Edited by J. R. Krebs and T. H. Clutton-Brock. Monographs in Behavior and Ecology. Princeton, University Press, Princeton, NJ, USA: Princeton University Press.\n\n\nWilson, Edward O. 1984. Biophiia. Cambridge, MA: : Harvard University Press."
  },
  {
    "objectID": "01-trees_and_people.html#deliverables",
    "href": "01-trees_and_people.html#deliverables",
    "title": "2  Tree Cover: an investigation in ecology and in environmental justice",
    "section": "2.3 Deliverables",
    "text": "2.3 Deliverables\nData analysis\n\nPost your two graphs, one from tree equity and one from i-Tree, to this Google Slide deck.\nInclude the information suggested on the slides (title that identifies main result, explanation of results, author names).\n\nWritten evaluation\n\nCompose a single document that contains answers to the above questions. I suggest that you start by simply listing answer to these questions. After you (our your group) is reasonably satisfied, compose a coherent essay between ~250-500 words that addresses the major points you want to convey.\nTurn this in as requested by your instructor."
  },
  {
    "objectID": "01-computer-setup.html#installing-r",
    "href": "01-computer-setup.html#installing-r",
    "title": "1  Computer setup",
    "section": "1.3 Installing R",
    "text": "1.3 Installing R\n\n1.3.1 What and Why\nWe will use the Open Source R programming language and environment for doing science, including,\n\nexploring data,\ntesting ideas, and\nmodeling dynamical systems like populations of rare and endangered species, disease dynamics, and ecosystems.\n\nYou need to download the application to get started.\n\nR is free.\nR runs on all operating systems.\nR is powerful.\n\n\n\n1.3.2 How\n\nFind out what version of operating system (OS) your computer is using (e.g., Windows 10 or 11, or Linux Ubuntu 22.04, or Mac Monterey or Ventura). This will help determine which version of R to use. If you are using a Mac, this also requires that you determine which version of processor or chip your computer uses (Intel processor vs. Apple M1 chip or higher). Check the processor or chip using the Apple icon menu in the upper left corner.\nGoogle R (just the letter “R”) to navigate to the R Project for Statistical Computing.\nFind the link in the left Task Bar for CRAN (Comprehensive R Archive Network).\nFind and navigate to a CRAN site near you (e.g., United States or Midwest US or Ohio). These are called mirrors because they are copies of each other.\nDownload and install the latest release of R for your operating system (Mac, Windows, or Linux).\nAs of January 2023, it was version 4.2.2. It is a single file to download. You should use whatever the latest version is.\nIn January 2023, it was worked like this:\n\nMac - select R-4.2.2.pkg (for the Intel chip) or R-4.2.2.arm64.pkg (for the Apple M1 chip)\nWindows - select the “base” package, then R 4.2.2\nLinux - select your flavor, and follow instructions.\n\n\n\n\n1.3.3 Where\n\nR and RStudio will be installed along side all your other applications.\n\n\n\n1.3.4 Installing RStudio\nRStudio is an integrated development environment (IDE), designed to be used with R. The R interface looks a little different on Windows, Macs, and Linux computers. RStudio will allow us all share an identical appearance and user experience.\n\nNavigate online to the RStudio website.\nUnder Products find RStudio IDE.\nSelect and download the Open Source Edition (RStudio Desktop). You want the desktop version (not the server version).\nFollow instructions to install on your computer.\n\nRStudio is an interface to R. When we use R in this class, we will use RStudio as our interface, but you need to realize that we are primarily using R. We don’t need RStudio to do the work, but it makes my job as instructor easier, and makes it a little easier for you as well. So, when you start to use R, just open RStudio, and it will load R for you.\n\n\n1.3.5 Windows tweak\nYou will need to be able to see file extensions on your computer. A file extension is the little label at the end of a file name that comes after the dot, such as\n\n.jpg or .jpeg is the extension for JPEG image files.\n.docx is the extension for Microsoft Word document files.\n.txt is the extension for plain text files.\n.xlsx is the extension for Microsoft Excel files. You will work with these.\n.csv is the extension for Comma Separated Value text files - these can be produced by spreadsheet applications. You will work with these.\n.R is the extension for R scripts. You will work with these.\n\nOn Windows 10, you need to make changes to see file extensions by revealing “hidden items”. Windows 10: 1. Open File Explorer; if you do not have an icon for this in the task bar; click Start, click Windows System, and then File Explorer.\n\n\n\nFinding File Explorer on Windows.\n\n\n\nClick the View tab in File Explorer\n\n\n\n\nView tab in File Explorer\n\n\n\nClick the box next to File name extensions to see file extensions.\nClick the box next to Hidden items to see hidden files.\n\nYou should now be able to see file name extensions (e.g., .docx, .R) and hidden files."
  },
  {
    "objectID": "01-computer-setup.html#goals",
    "href": "01-computer-setup.html#goals",
    "title": "1  Computer setup",
    "section": "1.1 Goals",
    "text": "1.1 Goals\n\nInstall R and RStudio\nSet up your computer to play well with R.\nBegin to learn how to use R."
  },
  {
    "objectID": "01-computer-setup.html#set-up-two-folders-for-this-class",
    "href": "01-computer-setup.html#set-up-two-folders-for-this-class",
    "title": "1  Computer setup",
    "section": "1.4 Set up two folders for this class",
    "text": "1.4 Set up two folders for this class\n\nSet up a folder for this class. Call it “BIO209W”. Do not name it “BIO 209W” or “Bio209W” or “ecology”. Just “BIO209W”. It will help us. I don’t really care where you put this folder, but I hope you have a place for all of your classes and you could put it there.\nNext, set up a subfolder inside BIO209W called “Rwork”. Do not call it “RWORK” or “R work” or anything - just “Rwork”. It will help us. A lot. Rwork will be your working directory, which is where R looks automatically for data and where it automatically puts output."
  },
  {
    "objectID": "01-computer-setup.html#working-in-r",
    "href": "01-computer-setup.html#working-in-r",
    "title": "1  Computer setup",
    "section": "1.5 Working in R",
    "text": "1.5 Working in R\nTo work in R in this class, we will open RStudio. It will open R for you.\n\n1.5.1 Set your working directory\nYour working directory is where R looks to find stuff. R can look anywhere you tell it to, but it looks automatically in your “working directory”. In this class, you should always use “Rwork” as your working directory.\nFirst, let’s find out what your current working directory is. We will GET your Working Directory with this code:\n\ngetwd()\n\n[1] \"/Users/stevenmh/Courses/intro_to_ecology\"\n\n\nThis tells me what R is using as my working directory right now. My current working directory will differ from yours.\nWhat do you get when you run this code? If it is NOT Rwork, use the “Session” pulldown menu in RStudio to Set Working Directory and then Choose your working directory and always choose Rwork (which should be inside BIO209W).\n\n\n1.5.2 Create a project\nRStudio allows you to organize your work in projects. Here we create a new project that we will call Rwork.\nThis requires that you already have a folder called “BIO209W” and a subfolder in that called “Rwork”.\n\nIn RStudio, use the File menu to select “New Project”, and select “Existing Directory”.\nIn that dialogue, navigate to “Rwork”, and select “Open.”\nSelect “Create Project”.\n\nRStudio will now shift the working directory to your Rwork directory. You can see evidence of this: in the upper right pane which should have Rwork identified in the upper right corner, or in the lower right pane in the Files tab.\nFrom now on in this course, make sure that you are using this project. You can open R by clicking the “Rwork.proj” file in your Rwork directory, or opening RStudio, and selecting the Rwork project in the upper right corner."
  },
  {
    "objectID": "01-computer-setup.html#start-and-save-a-script",
    "href": "01-computer-setup.html#start-and-save-a-script",
    "title": "1  Computer setup",
    "section": "1.6 Start and save a script",
    "text": "1.6 Start and save a script\nGoal: Write a script in R and learn several important programming operations.\nAfter you have prepared your computer as above, you are ready to begin exploring and modeling data. We do that using scripts.\nA script is a plain text file that contains the code and and your own comments that you use to address your questions.\nThe following steps will let you accomplish the goal of this section. The video above showed me opening R with RStudio, and starting a new script.\nWriting comments Anything following a hashtag (#) is a comment and R ignores it. You and I will use lots of comments to ask questions of ourselves, and to describe what we are trying to do.\n\nUse the File menu in RStudio to start a New File, specifically, an R Script. This will open a file in the upper left of RStudio.\nwrite the following in the new script, and include the hastags.\n\n\n## My first R script in BIO 209W Spring 2023\n## [add your name]\n\nALL OF THE WORK YOU DO SHOULD BE IN A SCRIPT.\n\n1.6.1 Entering and running code\nTo enter code, place your cursor on any line in the script, and type, like this.\n\n-1:5\n\nTo run code, simply place you cursor anywhere on a line of code and hit Control-Enter or Control-Return or Command-return (Mac).\nTry it with this:\n\n-1:5\n\n[1] -1  0  1  2  3  4  5\n\n\nThis will pop up in the Console, which is the lower left pane in RStudio.\nWhat did this create? Do you get what I got above?\n\n\n1.6.2 Assignment operator\nW?hen we create something, we typically want to assign it to a labeled object. In this class, we will use an arrow to indicate that we are putting a creation into an object. We create the arrow on our keyboard using shift-comma and a dash (‘less than’ and a dash)\n\na <- -1:5\n\nThis puts the series of integers from -1 to 10 into the object a.\n\n\n1.6.3 Examing objects\nIf we have an object, like a, how can we figure out what it is? There are several ways of doing that. The simplest is to “print” it out. This doesn’t mean that we print it on paper. Rather we are printing it to the console, like this:\n\n# show or 'print' a\na\n\n[1] -1  0  1  2  3  4  5\n\n\nAnother way is to look at its “structure”:\n\nstr(a)\n\n int [1:7] -1 0 1 2 3 4 5\n\n\nThis tells us that this is a vector of integers that is 7 elements long.\nAnother way is to look in the RStudio Environment pane in the upper righthand side of RStudio.\nNow let’s create a set of 7 uniformly distributed random numbers that are between 0 and 1.\n\nb <- runif(7, min=0, max=1)\nb\n\n[1] 0.7008348 0.9543264 0.2879969 0.3321163 0.2133224 0.2698934 0.8975368\n\n\nThese will differ every time you do this.\nNow we multiply each element in a times the corresponding elements in b.\n\n# multiply a and b\nab <- a * b\n## Show a, b, and ab\na\n\n[1] -1  0  1  2  3  4  5\n\nb\n\n[1] 0.7008348 0.9543264 0.2879969 0.3321163 0.2133224 0.2698934 0.8975368\n\nab\n\n[1] -0.7008348  0.0000000  0.2879969  0.6642325  0.6399671  1.0795738  4.4876838\n\n\nYou can confirm at a glance that the first and second elements in a times the first and second elements in b equal the first and second elements in ab.\n\n\n1.6.4 Combining vectors into a data frame\nWe will use lots of data frames in this course. Think of a data frame as a kind of spreadsheet of data, in which every column has the same number of entries and every row is an observation comprising all of the variables across all the columns.\nHere is one way to create a data frame. We assign variables using “=”.\n\nd <- data.frame(a=a, b=b, a_times_b = ab)\nd\n\n   a         b  a_times_b\n1 -1 0.7008348 -0.7008348\n2  0 0.9543264  0.0000000\n3  1 0.2879969  0.2879969\n4  2 0.3321163  0.6642325\n5  3 0.2133224  0.6399671\n6  4 0.2698934  1.0795738\n7  5 0.8975368  4.4876838\n\n\nYou could examine the structure of this data frame with str().\n\nstr(d)\n\n'data.frame':   7 obs. of  3 variables:\n $ a        : int  -1 0 1 2 3 4 5\n $ b        : num  0.701 0.954 0.288 0.332 0.213 ...\n $ a_times_b: num  -0.701 0 0.288 0.664 0.64 ...\n\n\nYou will also notice now that you can see all of our objects in the Environment pane, in the upper right of RStudio.\nYou can export data frames from R as well, and programmers call that “writing” a file. The command below will save our data frame as .CSV files that you could open in a spreadsheet application.\n\n# export or write a file\nwrite.csv(x=d, file=\"myDataframe.csv\", row.names=FALSE)\n# including row.names=FALSE prevents R from adding row names.\n\nThis should cause the data frame d to get saved to your working directory. Did it work for you?\n\n\n1.6.5 Plotting data\nNow let’s plot some data, including both points and lines connecting them.\n\n# type='p' is for points only\nplot(a, ab, type='p') \n\n\n\n\nR is well known for its graphics capabilities, and we will only just scratch the surface in this course."
  },
  {
    "objectID": "01-computer-setup.html#install-an-r-package",
    "href": "01-computer-setup.html#install-an-r-package",
    "title": "1  Computer setup",
    "section": "1.7 Install an R package",
    "text": "1.7 Install an R package\nR is open source, and its strength derives in part from the thousands of scientists creating extensions or add-on packages to do particular tasks. By itself, R can do amazing things. With thousands of contributed packages (as they are known), R’s capabilities have exploded.\nYou can add a package in a few ways, including.\n\nUse the Tools menu, select “install packages” and type the name of the package you want.\nuse a function, “install.packages(”[packagename]“), with quotes but without brackets.\n\nIn this class, you will need to install several packages. Let’s try installing “ggplot2”.\n\ninstall.packages(\"ggplot2\")\n\nThis will install ggplot2, and it will also install anything upon which ggplot2 depends. It will install all of its dependencies.\nOnce you have installed a package, it is on your computer for good. You do not have to install it again, although you may want to update it once in a while to stay current.\nNow let’s use the plotting functions in the ggplot2 package."
  },
  {
    "objectID": "01-computer-setup.html#load-and-use-an-r-package",
    "href": "01-computer-setup.html#load-and-use-an-r-package",
    "title": "1  Computer setup",
    "section": "1.8 Load and use an R package",
    "text": "1.8 Load and use an R package\nTo use a contributed package, we need to load it. This simply means waking it up, and putting its code in R’s working memeory. We do that with library().\n\nlibrary(ggplot2)\n\nHere we use ggplot() and geom_smooth() to plot our data, and add a fitted curve.\nWhen we use ggplot(), we tell it the name of our data frame and the variables we want to use go inside aes(), which stands for “aesthetics”. We also begin to add bells and whistles.\n\n## plot data and fit a curve\nggplot(data=d, aes(x=a, y=a_times_b)) + \n  geom_line() +\n  labs(x=\"a\", y=\"Product of a and b\")\n\n\n\n\nNote that with ggplot, we use the plus sign (+) to add elements to our graph.\n\n1.8.1 Saving your graphs\nWe can save this figure as well, in a variety of formats and sizes. By default, these are saved to our working directory, though we can change that if we want to.\n\nggsave(\"myPlot.png\")\n\nSaving 7 x 5 in image\n\nggsave(\"myPlot.jpg\", width=7, height = 3)\nggsave(\"myPlot.pdf\", width=3, height = 5)"
  },
  {
    "objectID": "01-computer-setup.html#deliverables",
    "href": "01-computer-setup.html#deliverables",
    "title": "1  Computer setup",
    "section": "1.10 Deliverables",
    "text": "1.10 Deliverables\nFor the “First R script” assignment on Canvas:\n\nUpload “myPlot.png” and “myDataframe.csv” to the .\nExplain your biggest surprise in this assignment.\n\nCongratulations. C’est fini!"
  },
  {
    "objectID": "01-computer-setup.html#congratulations.-cest-fini",
    "href": "01-computer-setup.html#congratulations.-cest-fini",
    "title": "1  Computer setup",
    "section": "1.10 Congratulations. C’est fini!",
    "text": "1.10 Congratulations. C’est fini!"
  },
  {
    "objectID": "01-computer-setup.html#getting-help",
    "href": "01-computer-setup.html#getting-help",
    "title": "1  Computer setup",
    "section": "1.9 Getting help",
    "text": "1.9 Getting help\nR has a bit of a learning curve. What should you do if you get stuck? It all depends what sort of problem it is.\n\nFirst, ask your partner.\nUse the Help tab in the lower right pane in RStudio. (Similarly, type ?mean in the Console to get help on the function mean().)\nAsk another classmate.\nAsk me.\nSearch online.\nDid I mention you could ask me?"
  },
  {
    "objectID": "02-global_temp_anomalies.html#goals",
    "href": "02-global_temp_anomalies.html#goals",
    "title": "3  A Fate of Earth",
    "section": "3.1 Goals",
    "text": "3.1 Goals\nIn this assignment, you will\n\nLearn about the history of our perspective on global warming.\nUse R to display estimates of global temperature anomalies.\nDescribe the current temperature trajectory.\nCompare and contrast changes in temperature between humans and Earth.\n\nVideo lecture on global warming and climate change:"
  },
  {
    "objectID": "02-global_temp_anomalies.html#background",
    "href": "02-global_temp_anomalies.html#background",
    "title": "3  A Fate of Earth",
    "section": "3.2 Background",
    "text": "3.2 Background\nThe year that you were born was much warmer than usual–and it won’t ever be that cool again in your lifetime.\nEarth is getting warmer due to human activities, it will push it well beyond what earth has experienced in hundreds of thousands of years. How and why Earth is warming has been known for many decades. In the early 1980’s, even Exxon’s scientists accurately predicted the global warming that has occurred because we failed to act to change our behavior.1\nIn this exercise, you’ll graph data from the National Centers for Environmental Information, part of NOAA (US Dept of Commerce). These temperatures are anomalies from a long term mean. The reference they use is the period from 1951-1980.\nUsing the R script, you will construct a 95% confidence interval on expected mean surface anomalies. A “95% confidence interval of a mean” is an interval, if so constructed, that would tend to include the true mean about 95% of the time, given many, many repeated experiments conducted under identical conditions. It is based on frequentist statistical methods. It is actually pretty difficult to interpret, but it is a standard measure of uncertainty. You will construct such an interval for past and future global surface temperature anomalies.\nOverthinking: Frequentist statistical methods (those that you will all attempt to learn in intro stats class) give you a P-value, which is the probability of your data or more extreme data, given that your null hypothesis is true (i.e., your model is correct). That’s weird. The data are real - they don’t need a probability. A 95% confidence interval is an interval that we construct in a way where we would capture a “true” effect 95% of the time we repeat the same experiment under the same conditions. In contrast, Bayesian statistics would give us what we actually want: the probability that our model or hypothesis is correct, given our data. That is called conditional probability and is what a Bayesian analysis would give you. We might do that later in the course."
  },
  {
    "objectID": "02-global_temp_anomalies.html#activity",
    "href": "02-global_temp_anomalies.html#activity",
    "title": "3  A Fate of Earth",
    "section": "3.3 Activity",
    "text": "3.3 Activity\n\nDownload “global_surface_anomalies.csv. Place it in you Rwork folder. This is a text file that you could open with a spreadsheet application, where the data in different columns are separated by commas (Comma-Separated-Values, i.e., a CSV file).\nOpen “global_surface_anomalies.csv” in a spreadsheet application and learn what is on\n\nthe first five lines\nthe sixth line\nthe remaining lines\n\nIn R, create a script file that you will call global_anomalies_YourUniqueID.R."
  },
  {
    "objectID": "02-global_temp_anomalies.html#r-code",
    "href": "02-global_temp_anomalies.html#r-code",
    "title": "3  A Fate of Earth",
    "section": "3.4 R code",
    "text": "3.4 R code\nBelow, we set up or work environment, load data, work with data, and then save deliverables. This work flow will be natural after a while.\n\n3.4.1 Set up\nFirst, we always select the appropriate project and working directory. I do this by…\n…glancing at the upper right corner:\n\n\n\nRStudio shows which project you are using in the upper-right corner\n\n\n…and by looking in the File tab in the lower right pane - that should be your working directory, which should be Rwork.\nThe next thing we do is load packages that we know we will need. Remember, you only need to install a package onto your computer once. We load contributed packages in each session that we need them. In this course, you should always load tidyverse, at a minimum.\n\n## load R packages\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0      ✔ purrr   1.0.1 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.5.0 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()"
  },
  {
    "objectID": "02-global_temp_anomalies.html#import-data",
    "href": "02-global_temp_anomalies.html#import-data",
    "title": "3  A Fate of Earth",
    "section": "3.5 Import data",
    "text": "3.5 Import data\nMake sure that the global surface temperature anomalies data set (“global_surface_anomalies.csv”) is in your working directory, Rwork.\nWe import or “read in” the data so that R can work on it. Here we put it in an object called temps. We skip lines in the file\n\n# read in data\ntemps <- read.csv(\"global_surface_anomalies.csv\", # file name\n                  skip=3, # skip these lines because they contain metadata.\n                  header = TRUE # Tell R that the first row is column namaes\n                  ) # last parenthesis"
  },
  {
    "objectID": "02-global_temp_anomalies.html#finding-out-information-about-the-temperature-anomalies",
    "href": "02-global_temp_anomalies.html#finding-out-information-about-the-temperature-anomalies",
    "title": "3  A Fate of Earth",
    "section": "3.6 Finding out information about the temperature anomalies",
    "text": "3.6 Finding out information about the temperature anomalies\nNext we take a peek at the data with a summary.\n\nsummary(temps)\n\n      year          deg_C         \n Min.   :1880   Min.   :-0.48000  \n 1st Qu.:1916   1st Qu.:-0.20000  \n Median :1951   Median :-0.06000  \n Mean   :1951   Mean   : 0.05993  \n 3rd Qu.:1986   3rd Qu.: 0.26500  \n Max.   :2022   Max.   : 1.02000  \n\n\nThis shows us the minimum, maximum and mean of each numeric variable.\nIt also shows us the 1st, 2nd, and 3rd quartiles. The median is the 2nd quartile. Quartiles are three divisions in ranked data, such they divide the data into four equal parts, or quarters. The 1st quartile is the value that divides the lowest 25% of the values from the larger values. The 2nd quartile (i.e.) is the value that divides the lower 50% from the upper 50% of the observations. The 3rd quartile is the value that divides the highest 25% of the observations from the lower values.\n\n3.6.1 Minimum and maximum\nI’d like to know when the minimum and the maximum occurred. To find this out, I’ll use a two step process: I will find the min and the max, and then I will use those to take a subset of the data frame where the anomaly is equal to either the minimum or equal to the maximum.\nFirst, I find the minimum and the maximum.\n\n## get the min and max\nmin.anomaly <- min(temps$deg_C)\nmax.anomaly <- max(temps$deg_C)\n\nNow, I will use these to take a subset of the data frame where the anomaly is equal to either the minimum or equal to the maximum. The “OR” operator is the vertical line that programmers call a pipe. On your keyboard, it is above the return or enter key.\n\n## use the min and the max\n# note the two equal signs, a pipe, and then two more equals signs.\nsubset(temps, deg_C==min.anomaly | deg_C==max.anomaly ) \n\n    year deg_C\n30  1909 -0.48\n141 2020  1.02\n\n\nThese show us all of the entries in our data that the anomaly is equal to the minimum OR equal to the maximum.\n\n\n3.6.2 Using a year\nHere I find out the average temperature anomaly in the year I was born. I want YOU to find out the anomaly in the year you were born.\n\n## Find the anomaly in the year you were born\nsubset(temps, year==1960) # use your year with two equal signs\n\n   year deg_C\n81 1960 -0.03\n\n\nIn my birth year, it was just a touch below the 1951-1980 average."
  },
  {
    "objectID": "02-global_temp_anomalies.html#plotting-information",
    "href": "02-global_temp_anomalies.html#plotting-information",
    "title": "3  A Fate of Earth",
    "section": "3.7 Plotting information",
    "text": "3.7 Plotting information\nHere we are going to start visually examining the anomalies.\nWe will create a linegraph using ggplot(). Our first step will create the graph, but it won’t display it right away. I include comments on each line to remind you what everything does.\n\n## we will create a plot object and stick it in \"p\"\np <- ggplot(data=temps, # the data frame to use\n       ## aes() stand for \"aesthetics\"\n       aes(x=year, y=deg_C), # define x and y variables to plot\n       ) + # closing parenthesis and add a plus sign to add another graphical element\n  geom_line() # the type of graph to plot using x and y\n\nIf you do this correctly it will seem as though nothing happened. If you did something wrong, you might get an error message in the console. If R can’t find the function “ggplot”, that is because you didn’t load tidyverse (or ggplot2 which is a subset of tidyverse). Another common error is an incomplete statement that might come from a missing parensthesis or something. In that case, R might think that you are not finished making your statement and it will keep adding plus signs so that you can finish your coding statement.\nNow we display the graph.\n\np\n\n\n\n\nHere we add a trend line using a fancy statistical smoothing technique. By default, it will include a grey uncertainty region.\n\n## add a trend line\np + geom_smooth(linetype=\"dashed\") \n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\nHere we add prettier, more descriptive labels. Add a line for the anomaly in 2002.\n\n# first find the anomaly in 2002\nanomaly.2002 <- temps$deg_C[temps$year==2002]\nanomaly.2002\n\n[1] 0.63\n\np + geom_smooth() + \n  labs(\n    y=\"Surface temp. anomaly (deg C)\", \n    subtitle=\"Relative to average 1951-1980\"\n    ) +\n  geom_hline(yintercept = anomaly.2002, linetype=3)\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'"
  },
  {
    "objectID": "02-global_temp_anomalies.html#predicting-future-anomalies",
    "href": "02-global_temp_anomalies.html#predicting-future-anomalies",
    "title": "3  A Fate of Earth",
    "section": "3.8 Predicting future anomalies",
    "text": "3.8 Predicting future anomalies\nMajor goals of science are understanding and prediction. We could spend a long time discussing the connection between these two, but form now, we just want to forecast want our future might look like.\nThe statistical details of this are way beyond this course, and they are not even the way you would do it if you were serious about. Nonetheless, it won’t be too far off, and the intuitive part applies generally to making any set of predictions. We will merely ask the computer to do some math to accomplish the following:\n\ncreate an educated guess for the temperature trend. This will include,\n\nuncertainty that comes from how much the anomalies bounce up and down from year to year, and\na trend that comes from averaging nearby values.\ninformation that nearby years may be more similar to each other than years that are really far apart.\n\ngiven the observed uncertainty and the trend, make an educated guess for future obervations, taking into account that each future year adds uncertainty that we can only guess at.\nMake a figure showing the future forecast.\n\nSo, lets start with step one. and create a statistical model of the observations. We start by loading another package.\n\n## Load a necessary R package\nlibrary(mgcv) # stands for \"Mixed GAM Computation Vehicle\"\n\nLoading required package: nlme\n\n\n\nAttaching package: 'nlme'\n\n\nThe following object is masked from 'package:dplyr':\n\n    collapse\n\n\nThis is mgcv 1.8-41. For overview type 'help(\"mgcv-package\")'.\n\n\nNow we ask R to fit the model. Don’t worry about the details of the code. You can ask me if you are interested.\n\n## Create the model\nmod <- gamm(deg_C ~ s(year),  # \"deg_C as a function of year\n            data=temps, # data frame\n          correlation = corCAR1(form=~year), # specify autocorrelation among samples\n          method=\"REML\" # fit using restricted maximum likelihood\n          )\n\nNext we have to decide what years we want predictions for. Let’s go for 50 more years, to 2072\n\n## years for fit and prediction\nyears = data.frame(year=1880:2072)\n\nNow we apply the model to past and future years and make a data frame and keep the uncertainty estimates it generates. We also combine our specified years with the model.\n\n## include uncertainty with se.fit = TRUE\npreds <- data.frame(\n  predict(mod$gam, newdata=years, type=\"response\", se.fit=TRUE) \n  )\n\n# combine columns of data frames\nmy.predictions <- cbind(years, preds)\n\nLet’s look at the first three rows of what we’ve made.\n\n# first three lines , and all columns\nmy.predictions[1:3, ]\n\n  year        fit     se.fit\n1 1880 -0.1838866 0.06192846\n2 1881 -0.1889206 0.05769149\n3 1882 -0.1939558 0.05368252\n\n\nThis shows that the first column is the year, the second (fit) is the expected local estimate, and the third (se.fit) is the estimate of the uncertainty, which is the standard error of the expected value.\nNow we’ll create 95% confidence intervals for each year. Confidence intervals are intervals which would contain the “true” value (if there is one) a specified proportion of times, if you repeated the experiment a really, really large number of times. Ninety-five percent confidence intervals exclude the lowest 2.5% and the upper 97.5% regions.\n\n### Create 95% confidence intervals\ncrit.t.low <- qt(0.025, df = df.residual(mod$gam))\ncrit.t.high <- qt(0.975, df = df.residual(mod$gam))\n\n### this requires that you loaded the tidyverse package\nmy.predictions <- my.predictions %>% # my data\n  ## transform the data set to include two new columns\n  transform(\n    upper.conf.lim=fit + (crit.t.high * se.fit),\n    lower.conf.lim=fit + (crit.t.low * se.fit))\n### \n## view the first three rows\nmy.predictions[1:3, ]\n\n  year        fit     se.fit upper.conf.lim lower.conf.lim\n1 1880 -0.1838866 0.06192846    -0.06142257     -0.3063506\n2 1881 -0.1889206 0.05769149    -0.07483520     -0.3030059\n3 1882 -0.1939558 0.05368252    -0.08779817     -0.3001133\n\n\nNow we see we’ve added upper and lower confidence intervals. Next we’ll create a graph of our predictions, using several particular graphical features.\n\n## basic data and x, y values\ng <- ggplot(data = my.predictions, aes(x = year, y = fit)) +\n  ## adding a wide region or band (a ribbon)\n  geom_ribbon(aes(ymin = lower.conf.lim, ymax = upper.conf.lim, \n                  x = year), \n              alpha = 0.2, fill = \"black\") + \n  ## add the expected local trend\n  geom_line() +\n  ## adding the points for each year\n  geom_point(data = temps, mapping = aes(x = year, y = deg_C),\n               inherit.aes = FALSE) + \n  ## add a better label for the y axis\n  labs(y = \"Global temp. anomaly\")  \n  ## simplify the image\n\n\n\n\nNow we show the graph we created.\n\ng\n\n\n\n\n\n\nThe grey area represents the 95% confidence interval for the trend observed years, and also for the trend in the future years. It gets wider because each year’s uncertainty compunds with the next year’s uncertainty. [Your figure will look a little different the this one.]\nFinally, we save your figure. This is the graph you should use for your assignment.\n\n## Save a PNG file to your working directory\n## THIS IS THE GRAPH TO INSERT INTO YOUR ASSIGNMENT\nggsave(\"Global_temps.png\", # name for your figure\n       plot=g, ## identify which graph you want to save,\n       height=5, width=5)"
  },
  {
    "objectID": "02-global_temp_anomalies.html#does-earth-have-a-fever",
    "href": "02-global_temp_anomalies.html#does-earth-have-a-fever",
    "title": "3  A Fate of Earth",
    "section": "3.9 Does Earth have a fever?",
    "text": "3.9 Does Earth have a fever?\nIn this last section, we ask whether Earth’s temperature may be a little too high by comparing it to a human who has a fever.\nFirst we calculate the percent increase in temperature for Earth over the past 70 years and a human experiencing a serious fever.\nAverage temperature for humans is 37 C, and a serious fever is considered 39 C, so an increase of 2 C.\nEarth’s 20th century average temperature is 13.9 C. Let’s calculate the increase since 1950.\n\n## First we take a subset of our data set.\na <- subset(temps, year==1950) \nb <- subset(temps, year==2022)\nincrease <- b$deg_C - a$deg_C\nincrease\n\n[1] 1.06\n\n\nNext we calculate these increases (fever and global warming) as percentage change.\n\n## percent increase for Earth\nperc.Earth <- increase / 13.9 * 100\n\n## percent increase for humans\nperc.fever <- 2/37 * 100\n\nperc.Earth; perc.fever\n\n[1] 7.625899\n\n\n[1] 5.405405\n\n\nSo, what do you think? Does Earth have a fever? In what ways do you think comparing temperature variation of Earth to that of a human is or is not a useful thing to do."
  },
  {
    "objectID": "02-global_temp_anomalies.html#questions-to-answer",
    "href": "02-global_temp_anomalies.html#questions-to-answer",
    "title": "3  A Fate of Earth",
    "section": "3.10 Questions to answer",
    "text": "3.10 Questions to answer\n\nWhat is a temperature anomaly?\nIn the file “global_surface_anomalies.csv”, what is on\n\nthe first three lines?\nthe fourth line?\nthe rest of the data?\n\nWhat are the minimum, median, and maximum anomalies?\nWhen (in what year) were the minimum and maximum anomalies?\nWhat was the global average surface temperature anomaly in the year you were born? Provide the year and the anomaly.\nWhat does the grey band in the figure represent, and why does it get wider in future years?\nExplain whether you think Earth currently does or does not have a fever, and whether comparing temperature variation of Earth to that of a human is or is not a useful thing to do."
  },
  {
    "objectID": "02-global_temp_anomalies.html#deliverables",
    "href": "02-global_temp_anomalies.html#deliverables",
    "title": "3  A Fate of Earth",
    "section": "3.11 Deliverables",
    "text": "3.11 Deliverables\nTurn these into the relevant Canvas assignment before the due date.\n\nPut all your answers, including your graph with the confidence interval, into a .doc or .docx file and make fit on a single page. Turn in your answers and your graph to the relevant Canvas assignment Make sure that your name is on the file in the header!\nIn a separate document, turn in your R script, named global_temps_YourUniqueID.R This must NOT be a Word document. It must be a .R file."
  },
  {
    "objectID": "01-computer-setup.html#background",
    "href": "01-computer-setup.html#background",
    "title": "1  Computer setup",
    "section": "1.2 Background",
    "text": "1.2 Background\nIn this project, you will download and install R, known formally as the R programming language and environment. You will also install RStudio, an integrated development environment (IDE), designed to be used with R. The R interface looks a little different on Windows, Macs, and Linux computers. RStudio will allow us all share an identical appearance and user experience. You will use R by opening RStudio.\nThese videos might be useful, although all the content and instructions are written in text below. Ranked in order of importance and convenience:\n\nInstalling R and RStudio\nSet up your computer and start to use R via RStudio\nSaving figures made with ggplot()\nIntroduction to ggplot2 (long - 20 min)"
  }
]